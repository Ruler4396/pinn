"""
ç”Ÿæˆå¸¦æœ‰çœŸå®ä¸–ç•Œå› ç´ çš„è®­ç»ƒæ•°æ®

åŒ…æ‹¬ï¼š
1. æµ‹é‡å™ªå£°
2. ç¨€ç–é‡‡æ ·
3. æ•°æ®ç¼ºå¤±
4. ä¼ æ„Ÿå™¨è¯¯å·®
5. ç³»ç»Ÿæ€§åå·®

ä½œè€…: PINNsé¡¹ç›®ç»„
åˆ›å»ºæ—¶é—´: 2025-11-19
"""

import os
import sys
import numpy as np
import h5py
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

try:
    import mph
    print("âœ… mphæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âš ï¸ mphæ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹æ•°æ®")


class RealisticDataGenerator:
    """ç”Ÿæˆå¸¦æœ‰çœŸå®ä¸–ç•Œå› ç´ çš„è®­ç»ƒæ•°æ®"""

    def __init__(self, output_dir=None):
        """
        åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º comsol_simulation/data
        """
        if output_dir is None:
            output_dir = project_root / "comsol_simulation" / "data"

        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # å™ªå£°å‚æ•°é…ç½®
        self.noise_configs = {
            'high_precision': {
                'velocity_std': 0.0005,      # é«˜ç²¾åº¦é€Ÿåº¦å™ªå£°
                'pressure_std': 5,            # é«˜ç²¾åº¦å‹åŠ›å™ªå£°
                'position_std': 0.0005,      # é«˜ç²¾åº¦ä½ç½®å™ªå£°
                'outlier_rate': 0.005,       # 0.5% å¼‚å¸¸å€¼
                'missing_rate': 0.02          # 2% æ•°æ®ç¼ºå¤±
            },
            'industrial': {
                'velocity_std': 0.002,       # å·¥ä¸šçº§é€Ÿåº¦å™ªå£°
                'pressure_std': 20,           # å·¥ä¸šçº§å‹åŠ›å™ªå£°
                'position_std': 0.002,       # å·¥ä¸šçº§ä½ç½®å™ªå£°
                'outlier_rate': 0.02,        # 2% å¼‚å¸¸å€¼
                'missing_rate': 0.05          # 5% æ•°æ®ç¼ºå¤±
            },
            'low_cost': {
                'velocity_std': 0.005,       # ä½æˆæœ¬é€Ÿåº¦å™ªå£°
                'pressure_std': 50,           # ä½æˆæœ¬å‹åŠ›å™ªå£°
                'position_std': 0.005,       # ä½æˆæœ¬ä½ç½®å™ªå£°
                'outlier_rate': 0.05,        # 5% å¼‚å¸¸å€¼
                'missing_rate': 0.10          # 10% æ•°æ®ç¼ºå¤±
            }
        }

        # ç¨€ç–é‡‡æ ·ç­–ç•¥
        self.sampling_strategies = {
            'uniform': {
                'density': 0.2,              # 20% é‡‡æ ·ç‡
                'method': 'random_uniform'    # éšæœºå‡åŒ€é‡‡æ ·
            },
            'boundary_focused': {
                'density': 0.15,             # 15% æ€»é‡‡æ ·ç‡
                'boundary_density': 0.3,     # è¾¹ç•Œ30%é‡‡æ ·ç‡
                'center_density': 0.05,      # ä¸­å¿ƒ5%é‡‡æ ·ç‡
                'method': 'boundary_focus'   # è¾¹ç•Œèšç„¦é‡‡æ ·
            },
            'feature_based': {
                'density': 0.12,
                'corner_density': 0.4,       # è§’è½40%é‡‡æ ·ç‡
                'inlet_outlet_density': 0.3, # å…¥å£å‡ºå£30%
                'method': 'feature_based'    # åŸºäºç‰¹å¾çš„é‡‡æ ·
            }
        }

    def load_clean_data(self, clean_data_path=None):
        """
        åŠ è½½å¹²å‡€çš„COMSOLæ•°æ®

        Args:
            clean_data_path: å¹²å‡€æ•°æ®æ–‡ä»¶è·¯å¾„

        Returns:
            dict: æ¸…å‡€æ•°æ®
        """
        if clean_data_path is None:
            # ä½¿ç”¨é»˜è®¤çš„ç¤ºä¾‹æ•°æ®
            clean_data_path = self.output_dir / "microchannel_data_20251119_141929.h5"

        if not clean_data_path.exists():
            print(f"âŒ æœªæ‰¾åˆ°å¹²å‡€æ•°æ®æ–‡ä»¶: {clean_data_path}")
            # ç”Ÿæˆç¤ºä¾‹æ•°æ®
            print("ğŸ”§ ç”Ÿæˆç¤ºä¾‹æ•°æ®...")
            from export_simulation_data import SimulationDataExporter
            exporter = SimulationDataExporter()
            return exporter.export_complete_data(use_sample_data=True)

        try:
            with h5py.File(clean_data_path, 'r') as h5file:
                data = {
                    'mesh': {
                        'x': h5file['mesh']['x'][:],
                        'y': h5file['mesh']['y'][:]
                    },
                    'solution': {
                        'u': h5file['solution']['u'][:],
                        'v': h5file['solution']['v'][:],
                        'p': h5file['solution']['p'][:]
                    },
                    'info': dict(h5file['info'].attrs)
                }

            print(f"âœ… æˆåŠŸåŠ è½½å¹²å‡€æ•°æ®: {len(data['mesh']['x'])} ä¸ªæ•°æ®ç‚¹")
            return data

        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None

    def add_measurement_noise(self, data, noise_config='industrial'):
        """
        æ·»åŠ æµ‹é‡å™ªå£°

        Args:
            data: å¹²å‡€æ•°æ®å­—å…¸
            noise_config: å™ªå£°é…ç½®åç§°

        Returns:
            dict: å¸¦å™ªå£°çš„æ•°æ®
        """
        config = self.noise_configs[noise_config]

        noisy_data = data.copy()

        # æ·»åŠ é«˜æ–¯å™ªå£°åˆ°é€Ÿåº¦åœº
        u_noise = np.random.normal(0, config['velocity_std'], len(data['solution']['u']))
        v_noise = np.random.normal(0, config['velocity_std'], len(data['solution']['v']))

        noisy_data['solution']['u_noisy'] = data['solution']['u'] + u_noise
        noisy_data['solution']['v_noisy'] = data['solution']['v'] + v_noise

        # æ·»åŠ é«˜æ–¯å™ªå£°åˆ°å‹åŠ›åœº
        p_noise = np.random.normal(0, config['pressure_std'], len(data['solution']['p']))
        noisy_data['solution']['p_noisy'] = data['solution']['p'] + p_noise

        # æ·»åŠ ä½ç½®å™ªå£°ï¼ˆä¼ æ„Ÿå™¨å®šä½è¯¯å·®ï¼‰
        x_noise = np.random.normal(0, config['position_std'], len(data['mesh']['x']))
        y_noise = np.random.normal(0, config['position_std'], len(data['mesh']['y']))

        noisy_data['mesh']['x_noisy'] = data['mesh']['x'] + x_noise
        noisy_data['mesh']['y_noisy'] = data['mesh']['y'] + y_noise

        # æ·»åŠ å¼‚å¸¸å€¼ï¼ˆä¼ æ„Ÿå™¨æ•…éšœï¼‰
        if config['outlier_rate'] > 0:
            num_points = len(data['solution']['u'])
            outlier_mask = np.random.random(num_points) < config['outlier_rate']

            # é€Ÿåº¦å¼‚å¸¸å€¼ï¼ˆå¤§å¹…åç¦»ï¼‰
            u_outlier = np.random.uniform(-0.01, 0.01, np.sum(outlier_mask))
            v_outlier = np.random.uniform(-0.01, 0.01, np.sum(outlier_mask))

            noisy_data['solution']['u_noisy'][outlier_mask] += u_outlier
            noisy_data['solution']['v_noisy'][outlier_mask] += v_outlier

            # å‹åŠ›å¼‚å¸¸å€¼
            p_outlier = np.random.uniform(-100, 100, np.sum(outlier_mask))
            noisy_data['solution']['p_noisy'][outlier_mask] += p_outlier

            print(f"âš ï¸ æ·»åŠ äº† {np.sum(outlier_mask)} ä¸ªå¼‚å¸¸å€¼ ({config['outlier_rate']*100:.1f}%)")

        # æ·»åŠ æ•°æ®ç¼ºå¤±ï¼ˆä¼ æ„Ÿå™¨æ•…éšœï¼‰
        if config['missing_rate'] > 0:
            num_points = len(data['solution']['u'])
            missing_mask = np.random.random(num_points) < config['missing_rate']

            noisy_data['missing_mask'] = missing_mask
            print(f"âš ï¸ æ·»åŠ äº† {np.sum(missing_mask)} ä¸ªç¼ºå¤±æ•°æ®ç‚¹ ({config['missing_rate']*100:.1f}%)")

        # è®°å½•å™ªå£°å‚æ•°
        noisy_data['noise_config'] = config
        noisy_data['noise_type'] = noise_config

        print(f"âœ… å·²æ·»åŠ  {noise_config} çº§åˆ«çš„æµ‹é‡å™ªå£°")
        return noisy_data

    def apply_sparse_sampling(self, data, sampling_strategy='boundary_focused'):
        """
        åº”ç”¨ç¨€ç–é‡‡æ ·ç­–ç•¥

        Args:
            data: å®Œæ•´æ•°æ®å­—å…¸
            sampling_strategy: é‡‡æ ·ç­–ç•¥åç§°

        Returns:
            dict: ç¨€ç–é‡‡æ ·çš„æ•°æ®
        """
        strategy = self.sampling_strategies[sampling_strategy]
        num_points = len(data['mesh']['x'])

        if strategy['method'] == 'random_uniform':
            # éšæœºå‡åŒ€é‡‡æ ·
            num_sample = int(num_points * strategy['density'])
            sample_indices = np.random.choice(num_points, num_sample, replace=False)

        elif strategy['method'] == 'boundary_focus':
            # è¾¹ç•Œèšç„¦é‡‡æ ·
            x_min, x_max = np.min(data['mesh']['x']), np.max(data['mesh']['x'])
            y_min, y_max = np.min(data['mesh']['y']), np.max(data['mesh']['y'])

            # è¯†åˆ«è¾¹ç•Œç‚¹ï¼ˆè·ç¦»è¾¹ç•Œ < 10% èŒƒå›´ï¼‰
            boundary_threshold_x = (x_max - x_min) * 0.1
            boundary_threshold_y = (y_max - y_min) * 0.1

            boundary_mask = (
                (np.abs(data['mesh']['x'] - x_min) < boundary_threshold_x) |
                (np.abs(data['mesh']['x'] - x_max) < boundary_threshold_x) |
                (np.abs(data['mesh']['y'] - y_min) < boundary_threshold_y) |
                (np.abs(data['mesh']['y'] - y_max) < boundary_threshold_y)
            )

            boundary_indices = np.where(boundary_mask)[0]
            center_indices = np.where(~boundary_mask)[0]

            # æŒ‰å¯†åº¦é‡‡æ ·
            num_boundary = int(len(boundary_indices) * strategy['boundary_density'])
            num_center = int(len(center_indices) * strategy['center_density'])

            sampled_boundary = np.random.choice(boundary_indices,
                                             min(num_boundary, len(boundary_indices)),
                                             replace=False)
            sampled_center = np.random.choice(center_indices,
                                           min(num_center, len(center_indices)),
                                           replace=False)

            sample_indices = np.concatenate([sampled_boundary, sampled_center])

        elif strategy['method'] == 'feature_based':
            # åŸºäºç‰¹å¾çš„é‡‡æ ·ï¼ˆå…¥å£ã€å‡ºå£ã€è§’è½ï¼‰
            x_min, x_max = np.min(data['mesh']['x']), np.max(data['mesh']['x'])
            y_min, y_max = np.min(data['mesh']['y']), np.max(data['mesh']['y'])

            # å®šä¹‰ç‰¹å¾åŒºåŸŸ
            inlet_region = data['mesh']['x'] < (x_min + (x_max - x_min) * 0.1)
            outlet_region = data['mesh']['x'] > (x_max - (x_max - x_min) * 0.1)

            corner_region = (
                ((data['mesh']['x'] < (x_min + (x_max - x_min) * 0.1)) |
                 (data['mesh']['x'] > (x_max - (x_max - x_min) * 0.1))) &
                ((data['mesh']['y'] < (y_min + (y_max - y_min) * 0.1)) |
                 (data['mesh']['y'] > (y_max - (y_max - y_min) * 0.1)))
            )

            inlet_indices = np.where(inlet_region & ~corner_region)[0]
            outlet_indices = np.where(outlet_region & ~corner_region)[0]
            corner_indices = np.where(corner_region)[0]
            remaining_indices = np.where(~(inlet_region | outlet_region | corner_region))[0]

            # æŒ‰å¯†åº¦é‡‡æ ·
            num_corner = int(len(corner_indices) * strategy['corner_density'])
            num_inlet_outlet = int((len(inlet_indices) + len(outlet_indices)) *
                                  strategy['inlet_outlet_density'])

            sampled_corner = np.random.choice(corner_indices,
                                           min(num_corner, len(corner_indices)),
                                           replace=False)
            sampled_inlet_outlet = np.random.choice(
                np.concatenate([inlet_indices, outlet_indices]),
                min(num_inlet_outlet, len(inlet_indices) + len(outlet_indices)),
                replace=False
            )

            sample_indices = np.concatenate([sampled_corner, sampled_inlet_outlet])

        # åˆ›å»ºç¨€ç–æ•°æ®
        sparse_data = {}
        for key in ['mesh', 'solution']:
            sparse_data[key] = {}
            for subkey in data[key]:
                if hasattr(data[key][subkey], '__len__'):
                    sparse_data[key][subkey] = data[key][subkey][sample_indices]
                else:
                    sparse_data[key][subkey] = data[key][subkey]

        # ä¿ç•™å…¶ä»–ä¿¡æ¯
        for key in data:
            if key not in ['mesh', 'solution']:
                sparse_data[key] = data[key]

        # è®°å½•é‡‡æ ·ä¿¡æ¯
        sparse_data['sampling_info'] = {
            'strategy': sampling_strategy,
            'original_points': num_points,
            'sampled_points': len(sample_indices),
            'sampling_ratio': len(sample_indices) / num_points,
            'sample_indices': sample_indices
        }

        print(f"âœ… åº”ç”¨ {sampling_strategy} é‡‡æ ·ç­–ç•¥: {len(sample_indices)}/{num_points} "
              f"({len(sample_indices)/num_points*100:.1f}%)")

        return sparse_data

    def generate_realistic_dataset(self, clean_data_path=None,
                                 noise_configs=['high_precision', 'industrial', 'low_cost'],
                                 sampling_strategies=['uniform', 'boundary_focused', 'feature_based']):
        """
        ç”Ÿæˆå®Œæ•´çš„å¤šåœºæ™¯çœŸå®æ•°æ®é›†

        Args:
            clean_data_path: å¹²å‡€æ•°æ®è·¯å¾„
            noise_configs: å™ªå£°é…ç½®åˆ—è¡¨
            sampling_strategies: é‡‡æ ·ç­–ç•¥åˆ—è¡¨

        Returns:
            list: ç”Ÿæˆçš„æ•°æ®é›†æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("ğŸš€ å¼€å§‹ç”ŸæˆçœŸå®æ•°æ®é›†...")

        # åŠ è½½å¹²å‡€æ•°æ®
        print("\nğŸ“ åŠ è½½å¹²å‡€æ•°æ®...")
        clean_data = self.load_clean_data(clean_data_path)

        if clean_data is None:
            print("âŒ æ— æ³•åŠ è½½å¹²å‡€æ•°æ®ï¼Œç»ˆæ­¢ç”Ÿæˆ")
            return []

        generated_files = []

        # ç”Ÿæˆä¸åŒå™ªå£°çº§åˆ«å’Œé‡‡æ ·ç­–ç•¥çš„ç»„åˆ
        for noise_config in noise_configs:
            for sampling_strategy in sampling_strategies:
                print(f"\nğŸ”§ ç”Ÿæˆåœºæ™¯: {noise_config} å™ªå£° + {sampling_strategy} é‡‡æ ·")

                # æ·»åŠ å™ªå£°
                noisy_data = self.add_measurement_noise(clean_data, noise_config)

                # åº”ç”¨ç¨€ç–é‡‡æ ·
                sparse_data = self.apply_sparse_sampling(noisy_data, sampling_strategy)

                # ä¿å­˜æ•°æ®
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"realistic_data_{noise_config}_{sampling_strategy}_{timestamp}.h5"
                output_path = self.output_dir / filename

                self.save_realistic_data(sparse_data, output_path)
                generated_files.append(output_path)

                print(f"âœ… å·²ä¿å­˜: {filename}")

        print(f"\nğŸ‰ æ•°æ®é›†ç”Ÿæˆå®Œæˆ! å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶")
        return generated_files

    def save_realistic_data(self, data, output_path):
        """
        ä¿å­˜çœŸå®æ•°æ®åˆ°HDF5æ–‡ä»¶

        Args:
            data: æ•°æ®å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            with h5py.File(output_path, 'w') as h5file:
                # ä¿å­˜åŸºæœ¬ä¿¡æ¯
                info_group = h5file.create_group('info')
                for key, value in data['info'].items():
                    info_group.attrs[key] = value

                # æ·»åŠ æ•°æ®é›†ç‰¹å¾ä¿¡æ¯
                info_group.attrs['creation_time'] = datetime.now().isoformat()
                info_group.attrs['data_type'] = 'realistic_simulation_data'
                info_group.attrs['noise_config'] = data.get('noise_type', 'unknown')
                info_group.attrs['sampling_strategy'] = data.get('sampling_info', {}).get('strategy', 'unknown')

                # ä¿å­˜ç½‘æ ¼æ•°æ®
                mesh_group = h5file.create_group('mesh')
                mesh_group.create_dataset('x', data=data['mesh']['x_noisy'] if 'x_noisy' in data['mesh'] else data['mesh']['x'])
                mesh_group.create_dataset('y', data=data['mesh']['y_noisy'] if 'y_noisy' in data['mesh'] else data['mesh']['y'])

                if 'sampling_info' in data:
                    mesh_group.attrs['sampling_info'] = str(data['sampling_info'])

                # ä¿å­˜æ±‚è§£æ•°æ®
                solution_group = h5file.create_group('solution')

                # ä¿å­˜å¸¦å™ªå£°çš„æ•°æ®ä½œä¸ºä¸»è¦æ•°æ®
                solution_group.create_dataset('u', data=data['solution']['u_noisy'] if 'u_noisy' in data['solution'] else data['solution']['u'])
                solution_group.create_dataset('v', data=data['solution']['v_noisy'] if 'v_noisy' in data['solution'] else data['solution']['v'])
                solution_group.create_dataset('p', data=data['solution']['p_noisy'] if 'p_noisy' in data['solution'] else data['solution']['p'])

                # å¦‚æœæœ‰å¹²å‡€æ•°æ®ï¼Œä¹Ÿä¿å­˜ä½œä¸ºå‚è€ƒ
                if 'u_noisy' in data['solution']:
                    solution_group.create_dataset('u_clean', data=data['solution']['u'])
                    solution_group.create_dataset('v_clean', data=data['solution']['v'])
                    solution_group.create_dataset('p_clean', data=data['solution']['p'])

                # ä¿å­˜ç¼ºå¤±æ•°æ®æ©ç 
                if 'missing_mask' in data:
                    solution_group.create_dataset('missing_mask', data=data['missing_mask'])

                # æ·»åŠ æ•°æ®å•ä½ä¿¡æ¯
                solution_group.attrs['u_unit'] = 'm/s'
                solution_group.attrs['v_unit'] = 'm/s'
                solution_group.attrs['p_unit'] = 'Pa'
                solution_group.attrs['x_unit'] = 'mm'
                solution_group.attrs['y_unit'] = 'mm'

                # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
                stats_group = h5file.create_group('statistics')

                for field in ['u', 'v', 'p']:
                    field_data = data['solution'][f'{field}_noisy' if f'{field}_noisy' in data['solution'] else field]
                    field_stats = stats_group.create_group(field)
                    field_stats.attrs['min'] = float(np.min(field_data))
                    field_stats.attrs['max'] = float(np.max(field_data))
                    field_stats.attrs['mean'] = float(np.mean(field_data))
                    field_stats.attrs['std'] = float(np.std(field_data))
                    field_stats.attrs['count'] = int(len(field_data))

                # å¦‚æœæœ‰å¹²å‡€æ•°æ®ï¼Œè®¡ç®—å™ªå£°ç»Ÿè®¡
                if 'u_noisy' in data['solution']:
                    noise_stats = stats_group.create_group('noise_analysis')
                    for field in ['u', 'v', 'p']:
                        clean_field = data['solution'][field]
                        noisy_field = data['solution'][f'{field}_noisy']
                        noise = noisy_field - clean_field

                        noise_field_stats = noise_stats.create_group(field)
                        noise_field_stats.attrs['noise_mean'] = float(np.mean(noise))
                        noise_field_stats.attrs['noise_std'] = float(np.std(noise))
                        noise_field_stats.attrs['noise_rms'] = float(np.sqrt(np.mean(noise**2)))
                        noise_field_stats.attrs['snr_db'] = float(10 * np.log10(np.var(clean_field) / np.var(noise)))

            print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            print(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")
            raise

    def visualize_realistic_data(self, data_path, save_plots=True):
        """
        å¯è§†åŒ–çœŸå®æ•°æ®

        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            save_plots: æ˜¯å¦ä¿å­˜å›¾è¡¨
        """
        try:
            with h5py.File(data_path, 'r') as h5file:
                x = h5file['mesh']['x'][:]
                y = h5file['mesh']['y'][:]
                u = h5file['solution']['u'][:]
                v = h5file['solution']['v'][:]
                p = h5file['solution']['p'][:]

                # è·å–å…ƒæ•°æ®
                noise_config = h5file['info'].attrs.get('noise_config', 'unknown')
                sampling_strategy = h5file['info'].attrs.get('sampling_strategy', 'unknown')

            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(2, 2, figsize=(12, 8))
            fig.suptitle(f'çœŸå®æ•°æ®å¯è§†åŒ– - {noise_config}å™ªå£° + {sampling_strategy}é‡‡æ ·',
                        fontsize=14)

            # é€Ÿåº¦å¹…å€¼
            speed = np.sqrt(u**2 + v**2)
            scatter1 = axes[0, 0].scatter(x, y, c=speed, s=1, cmap='viridis')
            axes[0, 0].set_title('é€Ÿåº¦å¹…å€¼ (m/s)')
            axes[0, 0].set_xlabel('X (mm)')
            axes[0, 0].set_ylabel('Y (mm)')
            axes[0, 0].set_aspect('equal')
            plt.colorbar(scatter1, ax=axes[0, 0])

            # Xæ–¹å‘é€Ÿåº¦
            scatter2 = axes[0, 1].scatter(x, y, c=u, s=1, cmap='RdBu_r')
            axes[0, 1].set_title('Xæ–¹å‘é€Ÿåº¦ (m/s)')
            axes[0, 1].set_xlabel('X (mm)')
            axes[0, 1].set_ylabel('Y (mm)')
            axes[0, 1].set_aspect('equal')
            plt.colorbar(scatter2, ax=axes[0, 1])

            # å‹åŠ›åœº
            scatter3 = axes[1, 0].scatter(x, y, c=p, s=1, cmap='coolwarm')
            axes[1, 0].set_title('å‹åŠ› (Pa)')
            axes[1, 0].set_xlabel('X (mm)')
            axes[1, 0].set_ylabel('Y (mm)')
            axes[1, 0].set_aspect('equal')
            plt.colorbar(scatter3, ax=axes[1, 0])

            # æ•°æ®åˆ†å¸ƒç»Ÿè®¡
            axes[1, 1].hist(speed, bins=30, alpha=0.7, label='é€Ÿåº¦å¹…å€¼')
            axes[1, 1].set_xlabel('é€Ÿåº¦å¹…å€¼ (m/s)')
            axes[1, 1].set_ylabel('é¢‘æ¬¡')
            axes[1, 1].set_title(f'æ•°æ®åˆ†å¸ƒ (n={len(x)})')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()

            if save_plots:
                output_path = self.output_dir / f"realistic_data_vis_{noise_config}_{sampling_strategy}.png"
                plt.savefig(output_path, dpi=150, bbox_inches='tight')
                print(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_path}")
            else:
                plt.show()

            plt.close()

        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ çœŸå®æ•°æ®é›†ç”Ÿæˆå™¨")
    print(f"ğŸ“… è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generator = RealisticDataGenerator()

    # ç”Ÿæˆæ•°æ®é›†
    try:
        generated_files = generator.generate_realistic_dataset(
            noise_configs=['high_precision', 'industrial'],  # å‡å°‘é…ç½®ä»¥åŠ å¿«é€Ÿåº¦
            sampling_strategies=['uniform', 'boundary_focused']
        )

        # ä¸ºæ¯ä¸ªç”Ÿæˆçš„æ–‡ä»¶åˆ›å»ºå¯è§†åŒ–
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        for file_path in generated_files:
            generator.visualize_realistic_data(file_path, save_plots=True)

        print(f"\nâœ… å®Œæˆ! ç”Ÿæˆäº† {len(generated_files)} ä¸ªçœŸå®æ•°æ®é›†æ–‡ä»¶")
        print("ğŸ“‚ æ–‡ä»¶ä¿å­˜åœ¨:", generator.output_dir)

        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®é›†æ‘˜è¦:")
        for file_path in generated_files:
            file_size = file_path.stat().st_size / 1024  # KB
            print(f"   {file_path.name}: {file_size:.1f} KB")

    except Exception as e:
        print(f"âŒ æ•°æ®é›†ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())