#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
COMSOLæ‰¹é‡æ•°æ®ç”Ÿæˆè„šæœ¬ - ä¼˜åŒ–ç‰ˆæœ¬
åˆ†æ‰¹å¤„ç†ï¼Œé™ä½å†…å­˜å ç”¨ï¼Œæé«˜ç¨³å®šæ€§

é’ˆå¯¹AMD R5 5500Uä¼˜åŒ–ï¼š
- åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹5ä¸ªæ¡ˆä¾‹
- è¿›åº¦ç›‘æ§å’Œé”™è¯¯æ¢å¤
- è‡ªåŠ¨é‡è¯•æœºåˆ¶
- èµ„æºæ¸…ç†

ä½œè€…: Claude
æ—¥æœŸ: 2025-11-19
"""

import os
import sys
import time
import json
import h5py
import numpy as np
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

try:
    import mph
    print("âœ… mphæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âŒ mphæ¨¡å—æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install mph")
    sys.exit(1)

class BatchDataGenerator:
    """æ‰¹é‡æ•°æ®ç”Ÿæˆå™¨ - é’ˆå¯¹ç§»åŠ¨CPUä¼˜åŒ–"""

    def __init__(self, batch_size=5, max_retries=2):
        """
        åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨

        Args:
            batch_size: æ¯æ‰¹å¤„ç†çš„æ¡ˆä¾‹æ•°é‡ (æ¨è5ä¸ªï¼Œé€‚åˆ6æ ¸CPU)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.batch_size = batch_size
        self.max_retries = max_retries
        self.comsol_path = r"E:\COMSOL63\Multiphysics\bin\win64\comsol.exe"

        # ç›®å½•è®¾ç½®
        self.output_dir = project_root / "comsol_simulation" / "data"
        self.models_dir = project_root / "comsol_simulation" / "models"
        self.logs_dir = project_root / "comsol_simulation" / "logs"

        # åˆ›å»ºç›®å½•
        for directory in [self.output_dir, self.models_dir, self.logs_dir]:
            directory.mkdir(parents=True, exist_ok=True)

        # å®šä¹‰å‚æ•°ç»„åˆ
        self.define_optimized_parameters()

        # çŠ¶æ€è·Ÿè¸ª
        self.total_cases = len(self.parameter_combinations)
        self.completed_cases = []
        self.failed_cases = []
        self.log_file = self.logs_dir / f"batch_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        print(f"ğŸš€ æ‰¹é‡æ•°æ®ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ¯æ‰¹å¤„ç†: {self.batch_size}ä¸ªæ¡ˆä¾‹")
        print(f"   - æ€»æ¡ˆä¾‹æ•°: {self.total_cases}")
        print(f"   - é¢„è®¡æ‰¹æ•°: {(self.total_cases + batch_size - 1) // batch_size}")

    def define_optimized_parameters(self):
        """å®šä¹‰ä¼˜åŒ–çš„å‚æ•°ç»„åˆ - ç¡®ä¿è®¡ç®—æ•ˆç‡å’Œæ•°æ®è´¨é‡"""

        # ä¼˜åŒ–å‚æ•°é€‰æ‹© - åŸºäºç‰©ç†åˆç†æ€§å’Œè®¡ç®—æ•ˆç‡
        inlet_velocities = [0.001, 0.01, 0.03, 0.05, 0.1]  # m/sï¼Œè¦†ç›–ä¸åŒRe
        channel_widths = [0.15, 0.20, 0.25]  # mmï¼Œæ ‡å‡†å¾®é€šé“å°ºå¯¸
        fluid_viscosities = [0.001, 0.01]  # PaÂ·sï¼Œæ°´å’Œè¾ƒç²˜æµä½“

        self.parameter_combinations = []

        for i, v_inlet in enumerate(inlet_velocities):
            for j, width in enumerate(channel_widths):
                for k, viscosity in enumerate(fluid_viscosities):

                    # è®¡ç®—é¢„ä¼°é›·è¯ºæ•°
                    re_estimate = 1000 * v_inlet * (width * 1e-3) / viscosity

                    case_id = f"case_{i+1:02d}_{j+1}_{k+1}"
                    params = {
                        'case_id': case_id,
                        'inlet_velocity': v_inlet,
                        'channel_width': width,
                        'fluid_viscosity': viscosity,
                        'channel_length': 10.0,  # mm
                        'fluid_density': 1000.0,  # kg/mÂ³
                        'outlet_pressure': 0.0,    # Pa
                        'estimated_reynolds': re_estimate,
                        'priority': 'high' if 1 < re_estimate < 100 else 'normal'  # ä¼˜å…ˆå¤„ç†åˆç†ReèŒƒå›´
                    }
                    self.parameter_combinations.append(params)

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        self.parameter_combinations.sort(key=lambda x: x['priority'], reverse=True)

        print(f"ğŸ“‹ å‚æ•°ç»„åˆå®šä¹‰å®Œæˆ:")
        print(f"   - å…¥å£é€Ÿåº¦èŒƒå›´: {min(inlet_velocities)} - {max(inlet_velocities)} m/s")
        print(f"   - é€šé“å®½åº¦èŒƒå›´: {min(channel_widths)*1000:.0f} - {max(channel_widths)*1000:.0f} Î¼m")
        print(f"   - æµä½“ç²˜åº¦: {fluid_viscosities} PaÂ·s")
        print(f"   - é›·è¯ºæ•°èŒƒå›´: {min([p['estimated_reynolds'] for p in self.parameter_combinations]):.1f} - {max([p['estimated_reynolds'] for p in self.parameter_combinations]):.1f}")

    def log_message(self, message, level="INFO"):
        """è®°å½•æ—¥å¿—ä¿¡æ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}\n"

        print(message)

        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry)

    def create_single_model(self, params, attempt=1):
        """åˆ›å»ºå•ä¸ªCOMSOLæ¨¡å‹ - ç®€åŒ–ç‰ˆï¼Œæé«˜æˆåŠŸç‡"""
        try:
            self.log_message(f"åˆ›å»ºæ¨¡å‹: {params['case_id']} (å°è¯• {attempt})")

            # ä½¿ç”¨è½»é‡çº§å®¢æˆ·ç«¯å¯åŠ¨
            client = mph.Client(self.comsol_path, cores=4)  # é™åˆ¶æ ¸å¿ƒä½¿ç”¨

            # åˆ›å»ºæ¨¡å‹
            model_name = f"microfluidic_{params['case_id']}"
            model = client.create(model_name)

            # 2Då‡ ä½•
            model.geom().create("geom1", 2)
            model.geom("geom1").lengthUnit("mm")

            # çŸ©å½¢é€šé“
            rect1 = model.geom("geom1").create("r1", "Rectangle")
            rect1.set("size", [params['channel_length'], params['channel_width']])
            rect1.set("pos", [0.0, 0.0])
            model.geom("geom1").run()

            # å±‚æµç‰©ç†åœº
            model.physics().create("spf", "LaminarFlow", "geom1")

            # ææ–™å±æ€§
            model.physics("spf").feature().create("defns", "DefaultNodeSettings")
            model.physics("spf").feature("defns").selection().all()
            model.physics("spf").feature("defns").set("rho", str(params['fluid_density']))
            model.physics("spf").feature("defns").set("mu", str(params['fluid_viscosity']))

            # è¾¹ç•Œæ¡ä»¶
            inlet = model.physics("spf").feature().create("in1", "InletVelocity", 2)
            inlet.selection().set([1])
            inlet.set("U0", str(params['inlet_velocity']))

            outlet = model.physics("spf").feature().create("out1", "OutletPressure", 2)
            outlet.selection().set([2])
            outlet.set("p0", str(params['outlet_pressure']))

            wall = model.physics("spf").feature().create("wall1", "Wall", 2)
            wall.selection().set([3, 4])

            # è‡ªé€‚åº”ç½‘æ ¼ - é’ˆå¯¹ç§»åŠ¨CPUä¼˜åŒ–
            model.mesh().create("mesh1", "geom1")
            element_size = max(params['channel_width'] / 8, params['channel_width'] / 15)  # å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
            model.mesh("mesh1").set("maxsize", element_size)
            model.mesh("mesh1").set("minsize", element_size / 4)
            model.mesh("mesh1").automatic(True)
            model.mesh("mesh1").run()

            # ç ”ç©¶
            study = model.study().create("std1")
            study.feature().create("stat", "Stationary")

            self.log_message(f"æ¨¡å‹åˆ›å»ºæˆåŠŸ: {params['case_id']}")
            return model, client

        except Exception as e:
            self.log_message(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {params['case_id']} - {str(e)}", "ERROR")
            return None, None

    def run_simulation_optimized(self, model, params):
        """è¿è¡Œä¼˜åŒ–çš„æ¨¡æ‹Ÿ"""
        try:
            self.log_message(f"å¼€å§‹æ¨¡æ‹Ÿ: {params['case_id']}")

            # è®¾ç½®æ±‚è§£å™¨å‚æ•° - é’ˆå¯¹ç§»åŠ¨CPUä¼˜åŒ–
            model.study("std1").feature("stat").set("solnum", "auto")
            model.study("std1").feature("stat").set("funclist", "all")

            # è¿è¡Œæ±‚è§£
            model.study("std1").run()

            self.log_message(f"æ¨¡æ‹Ÿå®Œæˆ: {params['case_id']}")
            return True

        except Exception as e:
            self.log_message(f"æ¨¡æ‹Ÿå¤±è´¥: {params['case_id']} - {str(e)}", "ERROR")
            return False

    def export_data_optimized(self, model, params):
        """ä¼˜åŒ–çš„æ•°æ®å¯¼å‡º"""
        try:
            self.log_message(f"å¯¼å‡ºæ•°æ®: {params['case_id']}")

            # åˆ›å»ºè¯„ä¼°ç»„
            model.result().numerical().create("eval1", "Eval")
            model.result().numerical("eval1").set("expr", ["u", "v", "p"])
            model.result().numerical("eval1").set("unit", ["m/s", "m/s", "Pa"])

            # ç”Ÿæˆæ•°æ®ç‚¹ - é™ä½å¯†åº¦ä»¥æé«˜é€Ÿåº¦
            grid_points = 30  # ä»50é™åˆ°30ï¼Œå‡å°‘è®¡ç®—é‡
            x_points = np.linspace(0, params['channel_length'], grid_points)
            y_points = np.linspace(0, params['channel_width'], grid_points)

            # æ‰¹é‡è¯„ä¼°
            results = []
            eval_points = []

            for x in x_points:
                for y in y_points:
                    eval_points.append([x, y])

            # åˆ†æ‰¹è¯„ä¼°ä»¥é¿å…å†…å­˜é—®é¢˜
            batch_eval_size = 100
            for i in range(0, len(eval_points), batch_eval_size):
                batch_points = eval_points[i:i+batch_eval_size]

                try:
                    for point in batch_points:
                        model.result().numerical("eval1").set("p", point)
                        values = model.result().numerical("eval1").getReal()
                        if len(values) >= 3:
                            results.append([point[0], point[1], values[0], values[1], values[2]])
                except:
                    continue

            # è½¬æ¢ä¸ºæ•°ç»„
            results = np.array(results)

            if len(results) == 0:
                self.log_message(f"æ— æœ‰æ•ˆæ•°æ®: {params['case_id']}", "ERROR")
                return False

            # ä¿å­˜åˆ°HDF5
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"batch_data_{params['case_id']}_{timestamp}.h5"
            filepath = self.output_dir / filename

            with h5py.File(filepath, 'w') as f:
                # æ•°æ®é›†
                f.create_dataset('x_coordinates', data=results[:, 0])
                f.create_dataset('y_coordinates', data=results[:, 1])
                f.create_dataset('velocity_u', data=results[:, 2])
                f.create_dataset('velocity_v', data=results[:, 3])
                f.create_dataset('pressure', data=results[:, 4])

                # ç»„åˆæ•°æ®ä¾¿äºè¯»å–
                f.create_dataset('coordinates', data=results[:, :2])
                f.create_dataset('velocity', data=results[:, 2:4])

                # å…ƒæ•°æ®
                for key, value in params.items():
                    if isinstance(value, (int, float)):
                        f.attrs[key] = value
                    else:
                        f.attrs[key] = str(value)

                # é¢å¤–ä¿¡æ¯
                f.attrs['total_points'] = len(results)
                f.attrs['grid_resolution'] = grid_points
                f.attrs['generation_time'] = timestamp
                f.attrs['reynolds_number'] = params['estimated_reynolds']

            self.log_message(f"æ•°æ®å¯¼å‡ºæˆåŠŸ: {filename} ({len(results)} æ•°æ®ç‚¹)")
            return True

        except Exception as e:
            self.log_message(f"æ•°æ®å¯¼å‡ºå¤±è´¥: {params['case_id']} - {str(e)}", "ERROR")
            return False

    def process_single_case(self, params):
        """å¤„ç†å•ä¸ªæ¡ˆä¾‹ - å¸¦é‡è¯•æœºåˆ¶"""
        for attempt in range(1, self.max_retries + 1):
            try:
                self.log_message(f"å¤„ç†æ¡ˆä¾‹: {params['case_id']} (å°è¯• {attempt}/{self.max_retries})")

                # åˆ›å»ºæ¨¡å‹
                model, client = self.create_single_model(params, attempt)
                if model is None:
                    continue

                # è¿è¡Œæ¨¡æ‹Ÿ
                if not self.run_simulation_optimized(model, params):
                    client.clear()
                    continue

                # å¯¼å‡ºæ•°æ®
                if not self.export_data_optimized(model, params):
                    client.clear()
                    continue

                # æˆåŠŸå®Œæˆ
                client.clear()
                return True

            except Exception as e:
                self.log_message(f"æ¡ˆä¾‹å¤„ç†å¼‚å¸¸: {params['case_id']} - {str(e)}", "ERROR")
                try:
                    client.clear()
                except:
                    pass

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        return False

    def process_batch(self, batch_params):
        """å¤„ç†ä¸€æ‰¹æ¡ˆä¾‹"""
        batch_start_time = time.time()
        self.log_message(f"\n{'='*50}")
        self.log_message(f"å¼€å§‹å¤„ç†æ–°æ‰¹æ¬¡ ({len(batch_params)} ä¸ªæ¡ˆä¾‹)")

        batch_success = 0

        for i, params in enumerate(batch_params):
            case_start_time = time.time()

            # æ˜¾ç¤ºæ¡ˆä¾‹ä¿¡æ¯
            re = params['estimated_reynolds']
            self.log_message(f"æ¡ˆä¾‹ {params['case_id']}: v={params['inlet_velocity']}m/s, "
                           f"w={params['channel_width']*1000:.0f}Î¼m, Î¼={params['fluid_viscosity']}PaÂ·s, Re={re:.1f}")

            # å¤„ç†æ¡ˆä¾‹
            if self.process_single_case(params):
                self.completed_cases.append(params['case_id'])
                batch_success += 1
                status = "âœ… æˆåŠŸ"
            else:
                self.failed_cases.append(params['case_id'])
                status = "âŒ å¤±è´¥"

            case_time = time.time() - case_start_time
            self.log_message(f"{status} - ç”¨æ—¶: {case_time:.1f}ç§’")

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()

        batch_time = time.time() - batch_start_time
        self.log_message(f"æ‰¹æ¬¡å®Œæˆ: {batch_success}/{len(batch_params)} æˆåŠŸ, ç”¨æ—¶: {batch_time/60:.1f}åˆ†é’Ÿ")

        return batch_success

    def run_all_batches(self):
        """è¿è¡Œæ‰€æœ‰æ‰¹æ¬¡"""
        start_time = time.time()
        total_batches = (self.total_cases + self.batch_size - 1) // self.batch_size

        self.log_message(f"\nğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆæ•°æ®")
        self.log_message(f"æ€»æ¡ˆä¾‹æ•°: {self.total_cases}")
        self.log_message(f"æ¯æ‰¹å¤§å°: {self.batch_size}")
        self.log_message(f"æ€»æ‰¹æ¬¡æ•°: {total_batches}")
        self.log_message(f"é¢„è®¡ç”¨æ—¶: {self.total_cases * 2 / 60:.1f} åˆ†é’Ÿ")

        # åˆ†æ‰¹å¤„ç†
        for batch_idx in range(total_batches):
            start_idx = batch_idx * self.batch_size
            end_idx = min(start_idx + self.batch_size, self.total_cases)
            batch_params = self.parameter_combinations[start_idx:end_idx]

            self.log_message(f"\nğŸ“ è¿›åº¦: æ‰¹æ¬¡ {batch_idx+1}/{total_batches}")

            # å¤„ç†å½“å‰æ‰¹æ¬¡
            self.process_batch(batch_params)

            # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
            progress = (batch_idx + 1) / total_batches * 100
            elapsed = time.time() - start_time
            if batch_idx > 0:
                eta = elapsed / (batch_idx + 1) * (total_batches - batch_idx - 1)
                self.log_message(f"ğŸ“Š æ€»è¿›åº¦: {progress:.1f}%, å·²ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ")

            # æ‰¹æ¬¡é—´ä¼‘æ¯ - è®©CPUå†·å´
            if batch_idx < total_batches - 1:
                self.log_message("â¸ï¸ æ‰¹æ¬¡é—´ä¼‘æ¯30ç§’...")
                time.sleep(30)

        # å®Œæˆç»Ÿè®¡
        total_time = time.time() - start_time
        success_rate = len(self.completed_cases) / self.total_cases * 100

        self.log_message(f"\n{'='*60}")
        self.log_message(f"ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        self.log_message(f"âœ… æˆåŠŸæ¡ˆä¾‹: {len(self.completed_cases)}/{self.total_cases} ({success_rate:.1f}%)")
        self.log_message(f"âŒ å¤±è´¥æ¡ˆä¾‹: {len(self.failed_cases)}")
        self.log_message(f"â° æ€»ç”¨æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        self.log_message(f"âš¡ å¹³å‡æ¯æ¡ˆä¾‹: {total_time/self.total_cases:.1f} ç§’")
        self.log_message(f"ğŸ“ æ•°æ®ä¿å­˜ä½ç½®: {self.output_dir}")
        self.log_message(f"ğŸ“‹ æ—¥å¿—æ–‡ä»¶: {self.log_file}")

        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        self.save_final_report(total_time, success_rate)

        return len(self.failed_cases) == 0

    def save_final_report(self, total_time, success_rate):
        """ä¿å­˜æœ€ç»ˆæŠ¥å‘Š"""
        try:
            report_file = self.output_dir / f"final_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            report = {
                "generation_info": {
                    "timestamp": datetime.now().isoformat(),
                    "total_cases": self.total_cases,
                    "successful_cases": len(self.completed_cases),
                    "failed_cases": len(self.failed_cases),
                    "success_rate": success_rate,
                    "total_time_minutes": total_time / 60,
                    "average_time_per_case": total_time / self.total_cases,
                    "batch_size": self.batch_size
                },
                "completed_cases": self.completed_cases,
                "failed_cases": self.failed_cases,
                "parameter_ranges": {
                    "inlet_velocity": [p['inlet_velocity'] for p in self.parameter_combinations],
                    "channel_width": [p['channel_width'] for p in self.parameter_combinations],
                    "fluid_viscosity": [p['fluid_viscosity'] for p in self.parameter_combinations],
                    "reynolds_range": [p['estimated_reynolds'] for p in self.parameter_combinations]
                },
                "system_info": {
                    "cpu_optimization": "AMD R5 5500U mobile optimized",
                    "batch_processing": True,
                    "memory_management": "enabled",
                    "retry_mechanism": f"{self.max_retries} attempts"
                }
            }

            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)

            self.log_message(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        except Exception as e:
            self.log_message(f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {str(e)}", "ERROR")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ COMSOLæ‰¹é‡æ•°æ®ç”Ÿæˆå™¨å¯åŠ¨")
    print("="*50)

    try:
        # åˆ›å»ºç”Ÿæˆå™¨ - é’ˆå¯¹6æ ¸ç§»åŠ¨CPUä¼˜åŒ–
        generator = BatchDataGenerator(batch_size=5, max_retries=2)

        # ç¡®è®¤æ‰§è¡Œ
        print(f"\nğŸ“‹ å‡†å¤‡ç”Ÿæˆ{generator.total_cases}ç»„æ•°æ®")
        print(f"âš¡ æ¯æ‰¹å¤„ç†5ä¸ªæ¡ˆä¾‹ï¼Œä¼˜åŒ–CPUä½¿ç”¨")
        print(f"â±ï¸  é¢„è®¡ç”¨æ—¶: {generator.total_cases * 2 / 60:.0f} åˆ†é’Ÿ")

        response = input("\nç¡®è®¤å¼€å§‹æ‰¹é‡ç”Ÿæˆ? (y/N): ").lower().strip()
        if response not in ['y', 'yes']:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return

        # æ‰§è¡Œæ‰¹é‡ç”Ÿæˆ
        success = generator.run_all_batches()

        if success:
            print("\nğŸ‰ æ‰€æœ‰æ•°æ®ç”ŸæˆæˆåŠŸ! å¯ä»¥å¼€å§‹PINNsè®­ç»ƒäº†!")
            print("ğŸ“‚ è¯·æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­çš„HDF5æ–‡ä»¶")
        else:
            print(f"\nâš ï¸  æœ‰{len(generator.failed_cases)}ä¸ªæ¡ˆä¾‹å¤±è´¥")
            print("ğŸ“‹ è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦æƒ…")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()